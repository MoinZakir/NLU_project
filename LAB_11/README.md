# LAB 11 - Sentiment Analysis/Opinion Mining

## Objectives
Understanding:
- Sentiment Analysis Tasks
  - Polarity Classification
  - Subjectivity Identification
  - Aspect/Feature-based Sentiment Analysis
- Supervised Sentiment Analysis
- Lexicon-based Sentiment Analysis
- Aspect-based Sentiment Analysis

Learning how to:
- Perform supervised polarity classification
- Use polarity/subjectivity lexicons for polarity and subjectivity detection
- Use negation and valence shifter in sentiment analysis
- Use dependency parsing for simple aspect extraction

## Lab Exercise
### Part 1: Subjectivity & Polarity
Create a pipeline model for Subjectivity and Polarity detection tasks. The pipeline has to be composed of two different models:
1. The first model predicts if a sentence is subjective or objective.
2. The second model performs the polarity detection of a document after removing the objective sentences predicted by the first model.

You have to report the results of the first and the second models. For the second model, you have to report the resutls achieved with and without the removal of the objective sentences to see if the pipeline can actually improve the performance.

Model:
- a Neutral Network in PyTorch (e.g. MLP or RNN), or
- a pre-trained language model (e.g. BERT or T5)

Datasets:
- NLTK: subjectivity (Subjectivity task)
- NLTK: movie reviews (Polarity task)

Evaluation:
- Use a K-fold evaluation for both tasks where with K = 10

References:
- [A sentimental education: Sentiment analysis using subjectivity](https://arxiv.org/pdf/cs/0409058.pdf)

### Part 2: Aspect Based Sentiment Analysis
Implement a joint model based on a Neural Network or a Pre-trained Language model for the Aspect Based Sentiment Analysis task:
1. Task 1: Extract the Aspect terms.
2. Task 2: Detect the polarity of these terms.

Dataset:
- The dataset that you have to use is the [Laptop partition of SemEval2014 task 4](https://github.com/lixin4ever/E2E-TBSA/tree/master/data).

Evaluation:
- For the evaluation you can refer to this [script](https://github.com/lixin4ever/E2E-TBSA/blob/master/evals.py) or the official script provided by [SemEval](https://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools) (Baseline, Evaluation and Evaluation link).
- Report F1, Precision and Recall for Task 1 alone, where you just consider the span ids, and jointly with Task2.
- You can jointly evaluate your model on these two tasks by considering both the span ids and polarity label in one single triple such as `(id_start, id_end, polarity)`.

References:
- [Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification](https://arxiv.org/pdf/1906.03820.pdf).

## Prerequisites
Before using the script, make sure you have the following dependencies installed:
- Python 3.x
- NLTK library
- SpaCy library
You can install the necessary dependencies using the following commands:
```bash
pip install nltk
pip install spacy
```

## Dataset
The dataset used for the first task of the Part 1 is [Subjectivity](https://paperswithcode.com/dataset/subj), containing collections of movie-review documents labeled with respect to their overall sentiment polarity (positive or negative) or subjective rating and sentences labeled with respect to their subjectivity status (subjective or objective) or polarity.
For the second task of the Part 1 we used [Movie Reviews](https://www.kaggle.com/datasets/vipulgandhi/movie-review-dataset) dataset, a collection of movie reviews retrieved from the imdb.com website collected and made available as part of researches on natural language processing. 
Please be aware that within the `dataset` folder, you'll discover two essential zip files: `polarity_subjective_sentences.zip` and `polarity_subjective_labels.zip`. These files correspond to the dataset used in the last task, generated by applying the `subjectivity.pt` model located in the `bin` folder within the [Movie Reviews](https://www.kaggle.com/datasets/vipulgandhi/movie-review-dataset) dataset. The purpose of these files is to eliminate objective sentences, thus allowing the completion of the second task in this exercise.

For the Part 2, has been assigned to use the [SemEval2014 Task 4](https://aclanthology.org/S14-2004.pdf), that aimed to foster research in the field of aspect-based sentiment analysis, where the goal is to identify the aspects of given target entities and the sentiment expressed for each aspect.

## Usage
Ensure you have all the necessary dependencies installed.

### Part 1
Inside this folder, you will find the code related to Part 1, where the output reports the results of the first and the second models. For the second model, have been reported the results achieved with and without the removal of the objective sentences, and we can see that the pipeline actually improve the performance.
1. Enter in the folder `part_1`.
2. Run the `main.py` script.
```bash
cd part_1
python main.py
```

NOTE: if the `trained = True` option has been considered in the main, the output will provide the main accuracy value on the whole dataset (in case of `subjectivity_polarity.pt` model the dataset used is `polarity_subjective_sentences.zip` and `polarity_subjective_labels.zip` for sentences and labels respectively, located in the folder `dataset`) for each of the best three models saved in the `/bin` folder, otherwise the training process will start again from the beginning for each model.

### Part 2
For the last part, the output provides the accuracy of our best model used subsequently for obtaining the final results for the Aspect Terms Extraction and Polarity Detection tasks.
1. Enter in the folder `part_2`.
2. Run the `main.py` script.
```bash
cd part_1
python main.py
```

NOTE: if the `trained = True` option has been considered in the main, the output will provide the test accuracy value for our best model saved in the `/bin` folder, otherwise the training process will start again from the beginning for the aforementioned model.
